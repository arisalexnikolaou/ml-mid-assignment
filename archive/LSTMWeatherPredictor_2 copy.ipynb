{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb58e9db",
   "metadata": {},
   "source": [
    "# Weather Prediction comparing Linear Regression vs LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd4b93",
   "metadata": {},
   "source": [
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np  # type: ignore\n",
    "import pandas as pd  # type: ignore\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler  # type: ignore MinMaxScaler performed more poorly\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  # type: ignore\n",
    "from tensorflow.keras.models import Sequential  # type: ignore\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout  # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # type: ignore\n",
    "\n",
    "from typing import Any  # noqa: E402\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "RANDOM_SEED: int = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "TARGET_COLUMN: str = \"MeanTemp\"  # the column to predict\n",
    "\n",
    "TRAIN_RATIO: float = 0.70  # proportion of data to use for training\n",
    "VALIDATION_RATIO: float = 0.15  # proportion of data to use for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4619342",
   "metadata": {},
   "source": [
    "## Test GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234df4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpus := tf.config.list_physical_devices(\"GPU\"):\n",
    "    print(f\"GPUs available: {gpus}\")\n",
    "    try:\n",
    "        # Optional: restrict TensorFlow to the first GPU\n",
    "        tf.config.set_visible_devices(gpus[0], \"GPU\")\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "        print(f\"Using GPU: {logical_gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU config error: {e}\")\n",
    "else:\n",
    "    print(\"No GPU found, running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e249918f",
   "metadata": {},
   "source": [
    "## Data Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9658e1",
   "metadata": {},
   "source": [
    "### Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3499f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH: Path = Path(\"Summary of Weather.csv\")\n",
    "\n",
    "df: pd.DataFrame = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8e138",
   "metadata": {},
   "source": [
    "### Show basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99610fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d42d0",
   "metadata": {},
   "source": [
    "### Drop columns with no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original columns:\", df.columns.tolist())\n",
    "print(len(df.columns))\n",
    "df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "print(\"Remaining columns:\", df.columns.tolist())\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc94e0",
   "metadata": {},
   "source": [
    "### Drop Meaningless Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"PoorWeather\", \"TSHDSBRSGF\", \"PRCP\"]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989cbf66",
   "metadata": {},
   "source": [
    "### Drop Duplicate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated columns: {df.duplicated().sum()}\")\n",
    "\n",
    "if df.duplicated().sum() > 0:\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "int(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129a5c4",
   "metadata": {},
   "source": [
    "## Select features and basic preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262adfe7",
   "metadata": {},
   "source": [
    "### Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS: list[str] = [\"STA\"]\n",
    "\n",
    "STANDARD_FEATURES: list[str] = [\n",
    "    \"STA\",  # station identifier, predictions should be grouped per station\n",
    "    # \"WindGustSpd\",\n",
    "    \"MaxTemp\",\n",
    "    \"MinTemp\",\n",
    "    \"MeanTemp\",\n",
    "    # \"PGT\",\n",
    "    # \"YR\",\n",
    "    \"MO\",\n",
    "    # \"DA\",\n",
    "    # added columns\n",
    "    \"DayOfYear\",\n",
    "]\n",
    "\n",
    "ROBUST_FEATURES: list[str] = [\"Snowfall\", \"Precip\"]\n",
    "\n",
    "ALL_FEATURES = STANDARD_FEATURES + ROBUST_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d9acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model: pd.DataFrame = df.copy()\n",
    "\n",
    "# Handle 'T' in precipitation-like columns if they exist\n",
    "for col in [\"Precip\", \"PRCP\"]:\n",
    "    if col in df_model.columns:\n",
    "        if df_model[col].dtype in (\"str\", \"object\"):\n",
    "            df_model[col] = df_model[col].replace(\"T\", 0.0)\n",
    "        # Cast to float\n",
    "        df_model[col] = pd.to_numeric(df_model[col], errors=\"coerce\")\n",
    "\n",
    "# Convert any remaining object columns that look numeric\n",
    "for col in df_model.columns:\n",
    "    if df_model[col].dtype == \"object\":\n",
    "        # Try to coerce to numeric, keep non-numeric as NaN\n",
    "        df_model[col] = pd.to_numeric(df_model[col], errors=\"coerce\")\n",
    "\n",
    "# Parse date and sort\n",
    "df_model[\"Date\"] = pd.to_datetime(df_model[\"Date\"])\n",
    "\n",
    "# add day of year feature for seasonality\n",
    "df_model[\"DayOfYear\"] = df_model[\"Date\"].dt.dayofyear\n",
    "\n",
    "df_model = df_model.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Keep only needed columns + Date for reference\n",
    "columns_to_use: list[str] = [\"Date\"] + ALL_FEATURES\n",
    "df_model = df_model[columns_to_use].copy()\n",
    "\n",
    "# Drop rows with any missing selected feature values\n",
    "df_model = df_model.dropna(subset=ALL_FEATURES).reset_index(drop=True)\n",
    "df_model.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006618ad",
   "metadata": {},
   "source": [
    "### Shared Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    title: str = \"Actual vs predicted MeanTemp\",\n",
    "    n_points: int = 300,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot actual vs predicted time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        True target values in original units.\n",
    "    y_pred : np.ndarray\n",
    "        Predicted target values in original units.\n",
    "    title : str\n",
    "        Title of the plot.\n",
    "    n_points : int\n",
    "        Number of last points to plot for readability.\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "    start: int = max(0, n - n_points)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(range(start, n), y_true[start:], label=\"Actual\")\n",
    "    plt.plot(range(start, n), y_pred[start:], label=\"Predicted\")\n",
    "    plt.xlabel(\"Time index (relative)\")\n",
    "    plt.ylabel(\"MeanTemp\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7f18b",
   "metadata": {},
   "source": [
    "## Linear Regression Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fddeda",
   "metadata": {},
   "source": [
    "### Train Linear Regresion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e33b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_linear = df_model.copy().dropna(subset=[TARGET_COLUMN]).reset_index(drop=True)\n",
    "\n",
    "target_candidates = [c for c in df.columns if c in [TARGET_COLUMN]]\n",
    "target_col = target_candidates[0]\n",
    "\n",
    "numeric_cols = df_clean_linear.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != target_col]\n",
    "\n",
    "X_lin = df_clean_linear[numeric_cols]\n",
    "y_lin = df_clean_linear[target_col]\n",
    "\n",
    "# --- Ensure no NaNs before splitting: impute with column means ---\n",
    "X_lin = X_lin.replace([np.inf, -np.inf], np.nan)  # just in case\n",
    "X_lin = X_lin.fillna(X_lin.mean())\n",
    "\n",
    "test_size = 1.0 - TRAIN_RATIO - VALIDATION_RATIO\n",
    "\n",
    "X_train_lin, X_test_lin, y_train_lin, y_lin_test = train_test_split(\n",
    "    X_lin, y_lin, test_size=test_size, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "X_test_lin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c58f3b7",
   "metadata": {},
   "source": [
    "### Run Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_lin, y_train_lin)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = lin_reg.predict(X_train_lin)\n",
    "y_test_pred = lin_reg.predict(X_test_lin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917cb54",
   "metadata": {},
   "source": [
    "### Validate Linear Regression Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44bc317",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse, train_rmse, train_mae, train_r2 = regression_metrics(\n",
    "    y_train_lin, y_train_pred\n",
    ")\n",
    "test_mse, test_rmse, test_mae, test_r2 = regression_metrics(y_lin_test, y_test_pred)\n",
    "\n",
    "print(\"=== Train metrics ===\")\n",
    "print(f\"MSE : {train_mse:.4f}\")\n",
    "print(f\"RMSE: {train_rmse:.4f}\")\n",
    "print(f\"MAE : {train_mae:.4f}\")\n",
    "print(f\"R²  : {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\n=== Test metrics ===\")\n",
    "print(f\"MSE : {test_mse:.4f}\")\n",
    "print(f\"RMSE: {test_rmse:.4f}\")\n",
    "print(f\"MAE : {test_mae:.4f}\")\n",
    "print(f\"R²  : {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d8a29",
   "metadata": {},
   "source": [
    "### Plot Predictions Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(y_lin_test.values, y_test_pred, n_points=300)\n",
    "\n",
    "print(len(y_lin_test.values))\n",
    "print(len(y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b803bd4",
   "metadata": {},
   "source": [
    "## LSTM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de210ac",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20485f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STA_WEIGHT: float = 2.0\n",
    "LOOKBACK: int = 14  # use last x days to predict next day\n",
    "PATIENCE: int = 3  # early stopping patience\n",
    "EPOCHS: int = 50  # maximum number of training epochs\n",
    "BATCH_SIZE: int = 64  # training batch size, reducing batch size improves accuracy but increases training time\n",
    "DENSE_LAYER: int = 64  # number of neurons in dense layer\n",
    "ACTIVATION: str = \"relu\"  # activation function for dense layer\n",
    "LSTM_UNITS: int = 256\n",
    "DROPOUT_RATE: float = 0.20  # dropout rate for regularization\n",
    "\n",
    "# scaler to use for data normalization\n",
    "# scaler: MinMaxScaler = MinMaxScaler(feature_range=(0, 1)) # performs worse than standard scaler\n",
    "standard_scaler: Any = StandardScaler() # to use in LSTM RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cbe7bd",
   "metadata": {},
   "source": [
    "### Build supervised sequences for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(\n",
    "    data: np.ndarray, target_index: int, lookback: int\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create (X, y) sequences for LSTM from multivariate time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Time-series data of shape (n_samples, n_features).\n",
    "    target_index : int\n",
    "        Index of the feature column to be predicted.\n",
    "    lookback : int\n",
    "        Number of past time steps used as input.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[np.ndarray, np.ndarray]\n",
    "        X of shape (n_sequences, lookback, n_features),\n",
    "        y of shape (n_sequences,).\n",
    "    \"\"\"\n",
    "    X_list: list[np.ndarray] = []\n",
    "    y_list: list[float] = []\n",
    "\n",
    "    for i in range(lookback, len(data)):\n",
    "        X_list.append(data[i - lookback : i])\n",
    "        y_list.append(data[i, target_index])\n",
    "\n",
    "    X: np.ndarray = np.array(X_list)\n",
    "    y: np.ndarray = np.array(y_list)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbc1e1",
   "metadata": {},
   "source": [
    "### Scaling and sequence creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d09279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature values\n",
    "features: np.ndarray = df_model[ALL_FEATURES].values\n",
    "\n",
    "scaled_features: np.ndarray = standard_scaler.fit_transform(features)\n",
    "\n",
    "target_index: int = ALL_FEATURES.index(TARGET_COLUMN)\n",
    "\n",
    "X_all, y_all = create_sequences(\n",
    "    data=scaled_features, target_index=target_index, lookback=LOOKBACK\n",
    ")\n",
    "\n",
    "X_all.shape, y_all.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0b154",
   "metadata": {},
   "source": [
    "### Train/validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(\n",
    "    X: np.ndarray, y: np.ndarray, train_ratio: float = 0.7, val_ratio: float = 0.15\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split time-series data into train, validation, and test partitions\n",
    "    preserving temporal order.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Input sequences of shape (n, lookback, n_features).\n",
    "    y : np.ndarray\n",
    "        Targets of shape (n,).\n",
    "    train_ratio : float\n",
    "        Fraction of samples for training.\n",
    "    val_ratio : float\n",
    "        Fraction of samples for validation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of arrays\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test.\n",
    "    \"\"\"\n",
    "    n_samples: int = len(X)\n",
    "    train_end: int = int(n_samples * train_ratio)\n",
    "    val_end: int = int(n_samples * (train_ratio + val_ratio))\n",
    "\n",
    "    X_train = X_all[:train_end]\n",
    "    y_train = y_all[:train_end]\n",
    "\n",
    "    X_val = X_all[train_end:val_end]\n",
    "    y_val = y_all[train_end:val_end]\n",
    "\n",
    "    X_test = X_all[val_end:]\n",
    "    y_test = y_all[val_end:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(\n",
    "    X_all, y_all, val_ratio=VALIDATION_RATIO, train_ratio=TRAIN_RATIO\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ba30d",
   "metadata": {},
   "source": [
    "### Define and train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(\n",
    "    input_shape: tuple[int, int],\n",
    "    lstm_units: int = 128,\n",
    "    dropout_rate: float = 0.5,\n",
    ") -> Sequential:\n",
    "    \"\"\"\n",
    "    Build a simple LSTM regression model in Keras.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : tuple[int, int]\n",
    "        Shape (lookback, n_features) for the input.\n",
    "    lstm_units : int\n",
    "        Number of LSTM units.\n",
    "    dropout_rate : float\n",
    "        Dropout rate after the LSTM layer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sequential\n",
    "        Compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(DENSE_LAYER, activation=ACTIVATION))\n",
    "    model.add(Dense(1))  # regression output\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape: tuple[int, int] = (X_train.shape[1], X_train.shape[2])\n",
    "model: Sequential = build_lstm_model(\n",
    "    input_shape=input_shape, lstm_units=LSTM_UNITS, dropout_rate=DROPOUT_RATE\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb7f34",
   "metadata": {},
   "source": [
    "Train model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39243b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c81595",
   "metadata": {},
   "source": [
    "### Visualize training loss and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history) -> None:\n",
    "    \"\"\"\n",
    "    Plot training and validation loss and MAE over epochs.\n",
    "    \"\"\"\n",
    "    history_dict = history.history\n",
    "    epochs = range(1, len(history_dict[\"loss\"]) + 1)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    axes[0].plot(epochs, history_dict[\"loss\"], label=\"Train loss (MSE)\")\n",
    "    axes[0].plot(epochs, history_dict[\"val_loss\"], label=\"Val loss (MSE)\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"Training and validation loss MSE\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epochs, history_dict[\"mae\"], label=\"Train MAE\")\n",
    "    axes[1].plot(epochs, history_dict[\"val_mae\"], label=\"Val MAE\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"MAE\")\n",
    "    axes[1].set_title(\"Training and validation MAE\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f6a06",
   "metadata": {},
   "source": [
    "### Evaluate on test set and compute scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_scaled: np.ndarray = model.predict(X_test)\n",
    "\n",
    "\n",
    "# For interpretability, inverse-transform MeanTemp back to original units.\n",
    "# We need to embed predictions into a full feature vector before inverse scaling.\n",
    "def inverse_transform_target(\n",
    "    scaled_target: np.ndarray,\n",
    "    scaler: Any,\n",
    "    target_index: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverse-transform a single target column that was part of a Scaler fit\n",
    "    on multiple features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scaled_target : np.ndarray\n",
    "        Predicted or true target values in scaled space, shape (n_samples, 1) or (n_samples,).\n",
    "    scaler : Any\n",
    "        Fitted scaler on the full feature matrix.\n",
    "    target_index : int\n",
    "        Index of the target column in the original feature matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Target values in original units, shape (n_samples,).\n",
    "    \"\"\"\n",
    "    scaled_target = np.asarray(scaled_target).reshape(-1, 1)\n",
    "    n_features: int = scaler.n_features_in_\n",
    "\n",
    "    # Create dummy zeros for all features, then replace target column\n",
    "    dummy_scaled = np.zeros((len(scaled_target), n_features))\n",
    "    dummy_scaled[:, target_index] = scaled_target[:, 0]\n",
    "\n",
    "    inv_full = scaler.inverse_transform(dummy_scaled)\n",
    "    return inv_full[:, target_index]\n",
    "\n",
    "\n",
    "y_test_inv: np.ndarray = inverse_transform_target(y_test, standard_scaler, target_index)\n",
    "y_pred_test_inv: np.ndarray = inverse_transform_target(\n",
    "    y_pred_test_scaled, standard_scaler, target_index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811483cd",
   "metadata": {},
   "source": [
    "### Validate Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse, test_rmse, test_mae, test_r2 = regression_metrics(y_test_inv, y_pred_test_inv)\n",
    "\n",
    "print(\"\\n=== Test metrics ===\")\n",
    "print(f\"MSE : {test_mse:.4f}\")\n",
    "print(f\"RMSE: {test_rmse:.4f}\")\n",
    "print(f\"MAE : {test_mae:.4f}\")\n",
    "print(f\"R²  : {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2a6f7",
   "metadata": {},
   "source": [
    "### Predictions vs Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(y_test_inv, y_pred_test_inv, n_points=300)\n",
    "\n",
    "print(len(y_test_inv))\n",
    "print(len(y_pred_test_inv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c89f6",
   "metadata": {},
   "source": [
    "### Residual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals: np.ndarray = y_test_inv - y_pred_test_inv\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(residuals)\n",
    "plt.axhline(0, color=\"black\", linewidth=1)\n",
    "plt.xlabel(\"Time index (test set)\")\n",
    "plt.ylabel(\"Residual (Actual - Predicted)\")\n",
    "plt.title(\"Residuals over time\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

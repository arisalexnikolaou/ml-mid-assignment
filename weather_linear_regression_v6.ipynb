{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Temperature Prediction using Linear Regression with Station Identification\n",
    "This notebook demonstrates temperature prediction using Linear Regression, incorporating weather station identifiers (STA) for station-specific analysis.\n",
    "\n",
    "**Data Source:** Summary of Weather.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List, Optional, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data with Station Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded successfully from Summary of Weather.csv\n",
      "üìä Shape: (119040, 31)\n",
      "\n",
      "üìã Columns: ['STA', 'Date', 'Precip', 'WindGustSpd', 'MaxTemp', 'MinTemp', 'MeanTemp', 'Snowfall', 'PoorWeather', 'YR', 'MO', 'DA', 'PRCP', 'DR', 'SPD', 'MAX', 'MIN', 'MEA', 'SNF', 'SND', 'FT', 'FB', 'FTI', 'ITH', 'PGT', 'TSHDSBRSGF', 'SD3', 'RHX', 'RHN', 'RVG', 'WTE']\n",
      "\n",
      "üè¢ Number of unique stations: 159\n",
      "üè¢ Station IDs: [10001 10002 10101 10102 10502 10505 10701 10703 10704 10705]...\n",
      "\n",
      "üìä Records per station (top 5):\n",
      "STA\n",
      "22508    2192\n",
      "10701    2185\n",
      "22502    2154\n",
      "22504    2118\n",
      "10803    1750\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üëÄ First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precip</th>\n",
       "      <th>WindGustSpd</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>PoorWeather</th>\n",
       "      <th>YR</th>\n",
       "      <th>...</th>\n",
       "      <th>FB</th>\n",
       "      <th>FTI</th>\n",
       "      <th>ITH</th>\n",
       "      <th>PGT</th>\n",
       "      <th>TSHDSBRSGF</th>\n",
       "      <th>SD3</th>\n",
       "      <th>RHX</th>\n",
       "      <th>RHN</th>\n",
       "      <th>RVG</th>\n",
       "      <th>WTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-1</td>\n",
       "      <td>1.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.888889</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-3</td>\n",
       "      <td>2.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.111111</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STA      Date Precip  WindGustSpd    MaxTemp    MinTemp   MeanTemp  \\\n",
       "0  10001  1942-7-1  1.016          NaN  25.555556  22.222222  23.888889   \n",
       "1  10001  1942-7-2      0          NaN  28.888889  21.666667  25.555556   \n",
       "2  10001  1942-7-3   2.54          NaN  26.111111  22.222222  24.444444   \n",
       "3  10001  1942-7-4   2.54          NaN  26.666667  22.222222  24.444444   \n",
       "4  10001  1942-7-5      0          NaN  26.666667  21.666667  24.444444   \n",
       "\n",
       "  Snowfall PoorWeather  YR  ...  FB  FTI ITH  PGT  TSHDSBRSGF  SD3  RHX  RHN  \\\n",
       "0      0.0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "1      0.0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "2      0.0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "3      0.0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "4      0.0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "\n",
       "  RVG  WTE  \n",
       "0 NaN  NaN  \n",
       "1 NaN  NaN  \n",
       "2 NaN  NaN  \n",
       "3 NaN  NaN  \n",
       "4 NaN  NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_weather_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load weather data from CSV file with station identification.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing weather data with STA column\n",
    "    \"\"\"\n",
    "    df: pd.DataFrame = pd.read_csv(file_path)\n",
    "    print(f\"‚úÖ Data loaded successfully from {file_path}\")\n",
    "    print(f\"üìä Shape: {df.shape}\")\n",
    "    print(f\"\\nüìã Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Display station information\n",
    "    if 'STA' in df.columns:\n",
    "        unique_stations: np.ndarray = df['STA'].unique()\n",
    "        print(f\"\\nüè¢ Number of unique stations: {len(unique_stations)}\")\n",
    "        print(f\"üè¢ Station IDs: {unique_stations[:10]}{'...' if len(unique_stations) > 10 else ''}\")\n",
    "        \n",
    "        # Station data distribution\n",
    "        station_counts: pd.Series = df['STA'].value_counts()\n",
    "        print(f\"\\nüìä Records per station (top 5):\")\n",
    "        print(station_counts.head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the Summary of Weather.csv file\n",
    "file_path: str = 'Summary of Weather.csv'\n",
    "df: pd.DataFrame = load_weather_data(file_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüëÄ First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Info:\n",
      "======================================================================\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 119040 entries, 0 to 119039\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   STA          119040 non-null  int64  \n",
      " 1   Date         119040 non-null  str    \n",
      " 2   Precip       119040 non-null  str    \n",
      " 3   WindGustSpd  532 non-null     float64\n",
      " 4   MaxTemp      119040 non-null  float64\n",
      " 5   MinTemp      119040 non-null  float64\n",
      " 6   MeanTemp     119040 non-null  float64\n",
      " 7   Snowfall     117877 non-null  object \n",
      " 8   PoorWeather  34237 non-null   object \n",
      " 9   YR           119040 non-null  int64  \n",
      " 10  MO           119040 non-null  int64  \n",
      " 11  DA           119040 non-null  int64  \n",
      " 12  PRCP         117108 non-null  str    \n",
      " 13  DR           533 non-null     float64\n",
      " 14  SPD          532 non-null     float64\n",
      " 15  MAX          118566 non-null  float64\n",
      " 16  MIN          118572 non-null  float64\n",
      " 17  MEA          118542 non-null  float64\n",
      " 18  SNF          117877 non-null  object \n",
      " 19  SND          5563 non-null    float64\n",
      " 20  FT           0 non-null       float64\n",
      " 21  FB           0 non-null       float64\n",
      " 22  FTI          0 non-null       float64\n",
      " 23  ITH          0 non-null       float64\n",
      " 24  PGT          525 non-null     float64\n",
      " 25  TSHDSBRSGF   34237 non-null   object \n",
      " 26  SD3          0 non-null       float64\n",
      " 27  RHX          0 non-null       float64\n",
      " 28  RHN          0 non-null       float64\n",
      " 29  RVG          0 non-null       float64\n",
      " 30  WTE          0 non-null       float64\n",
      "dtypes: float64(20), int64(4), object(4), str(3)\n",
      "memory usage: 28.2+ MB\n",
      "\n",
      "üìà Statistical Summary:\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>WindGustSpd</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>DR</th>\n",
       "      <th>SPD</th>\n",
       "      <th>...</th>\n",
       "      <th>FT</th>\n",
       "      <th>FB</th>\n",
       "      <th>FTI</th>\n",
       "      <th>ITH</th>\n",
       "      <th>PGT</th>\n",
       "      <th>SD3</th>\n",
       "      <th>RHX</th>\n",
       "      <th>RHN</th>\n",
       "      <th>RVG</th>\n",
       "      <th>WTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>119040.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29659.435795</td>\n",
       "      <td>37.774534</td>\n",
       "      <td>27.045111</td>\n",
       "      <td>17.789511</td>\n",
       "      <td>22.411631</td>\n",
       "      <td>43.805284</td>\n",
       "      <td>6.726016</td>\n",
       "      <td>15.797530</td>\n",
       "      <td>26.998124</td>\n",
       "      <td>20.396617</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.085333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20953.209402</td>\n",
       "      <td>10.297808</td>\n",
       "      <td>8.717817</td>\n",
       "      <td>8.334572</td>\n",
       "      <td>8.297982</td>\n",
       "      <td>1.136718</td>\n",
       "      <td>3.425561</td>\n",
       "      <td>8.794541</td>\n",
       "      <td>15.221732</td>\n",
       "      <td>5.560371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.731328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>18.520000</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-38.333333</td>\n",
       "      <td>-35.555556</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11801.000000</td>\n",
       "      <td>29.632000</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22508.000000</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>29.444444</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33501.000000</td>\n",
       "      <td>43.059000</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>27.222222</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82506.000000</td>\n",
       "      <td>75.932000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>34.444444</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STA  WindGustSpd        MaxTemp        MinTemp  \\\n",
       "count  119040.000000   532.000000  119040.000000  119040.000000   \n",
       "mean    29659.435795    37.774534      27.045111      17.789511   \n",
       "std     20953.209402    10.297808       8.717817       8.334572   \n",
       "min     10001.000000    18.520000     -33.333333     -38.333333   \n",
       "25%     11801.000000    29.632000      25.555556      15.000000   \n",
       "50%     22508.000000    37.040000      29.444444      21.111111   \n",
       "75%     33501.000000    43.059000      31.666667      23.333333   \n",
       "max     82506.000000    75.932000      50.000000      34.444444   \n",
       "\n",
       "            MeanTemp             YR             MO             DA          DR  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000  533.000000   \n",
       "mean       22.411631      43.805284       6.726016      15.797530   26.998124   \n",
       "std         8.297982       1.136718       3.425561       8.794541   15.221732   \n",
       "min       -35.555556      40.000000       1.000000       1.000000    2.000000   \n",
       "25%        20.555556      43.000000       4.000000       8.000000   11.000000   \n",
       "50%        25.555556      44.000000       7.000000      16.000000   32.000000   \n",
       "75%        27.222222      45.000000      10.000000      23.000000   34.000000   \n",
       "max        40.000000      45.000000      12.000000      31.000000   78.000000   \n",
       "\n",
       "              SPD  ...   FT   FB  FTI  ITH         PGT  SD3  RHX  RHN  RVG  \\\n",
       "count  532.000000  ...  0.0  0.0  0.0  0.0  525.000000  0.0  0.0  0.0  0.0   \n",
       "mean    20.396617  ...  NaN  NaN  NaN  NaN   12.085333  NaN  NaN  NaN  NaN   \n",
       "std      5.560371  ...  NaN  NaN  NaN  NaN    5.731328  NaN  NaN  NaN  NaN   \n",
       "min     10.000000  ...  NaN  NaN  NaN  NaN    0.000000  NaN  NaN  NaN  NaN   \n",
       "25%     16.000000  ...  NaN  NaN  NaN  NaN    8.500000  NaN  NaN  NaN  NaN   \n",
       "50%     20.000000  ...  NaN  NaN  NaN  NaN   11.600000  NaN  NaN  NaN  NaN   \n",
       "75%     23.250000  ...  NaN  NaN  NaN  NaN   15.000000  NaN  NaN  NaN  NaN   \n",
       "max     41.000000  ...  NaN  NaN  NaN  NaN   23.900000  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       WTE  \n",
       "count  0.0  \n",
       "mean   NaN  \n",
       "std    NaN  \n",
       "min    NaN  \n",
       "25%    NaN  \n",
       "50%    NaN  \n",
       "75%    NaN  \n",
       "max    NaN  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data information\n",
    "print(\"üìä Data Info:\")\n",
    "print(\"=\" * 70)\n",
    "df.info()\n",
    "\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "print(\"=\" * 70)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Station Selection and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Auto-selected station 22508 with 2192 records\n",
      "üìä Station 22508 data shape: (2192, 31)\n",
      "\n",
      "‚úÖ Working with Station ID: 22508\n"
     ]
    }
   ],
   "source": [
    "def select_station_data(df: pd.DataFrame, station_id: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Select data for a specific station or the station with most records.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with STA column\n",
    "        station_id: Specific station ID to select (None = auto-select largest)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame filtered for the selected station\n",
    "    \"\"\"\n",
    "    if 'STA' not in df.columns:\n",
    "        print(\"‚ö†Ô∏è  No STA column found, using all data\")\n",
    "        return df\n",
    "    \n",
    "    if station_id is None:\n",
    "        # Select station with most records\n",
    "        station_counts: pd.Series = df['STA'].value_counts()\n",
    "        station_id = station_counts.index[0]\n",
    "        print(f\"üéØ Auto-selected station {station_id} with {station_counts.iloc[0]} records\")\n",
    "    else:\n",
    "        if station_id not in df['STA'].values:\n",
    "            print(f\"‚ö†Ô∏è  Station {station_id} not found in data\")\n",
    "            return pd.DataFrame()\n",
    "        print(f\"üéØ Selected station {station_id}\")\n",
    "    \n",
    "    df_station: pd.DataFrame = df[df['STA'] == station_id].copy()\n",
    "    print(f\"üìä Station {station_id} data shape: {df_station.shape}\")\n",
    "    \n",
    "    return df_station\n",
    "\n",
    "# Select station data (change station_id to select a specific station, or leave None for auto-select)\n",
    "selected_station_id: Optional[int] = None  # Set to specific station ID or None\n",
    "df_station: pd.DataFrame = select_station_data(df, selected_station_id)\n",
    "\n",
    "# Store the selected station ID for later use\n",
    "if 'STA' in df_station.columns and len(df_station) > 0:\n",
    "    selected_station_id = df_station['STA'].iloc[0]\n",
    "    print(f\"\\n‚úÖ Working with Station ID: {selected_station_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data preprocessing completed!\n",
      "üìä Processed data shape: (2192, 40)\n",
      "üéØ Target variable: 'MeanTemp'\n",
      "üìÖ Date range: 1940-01-01 00:00:00 to 1945-12-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precip</th>\n",
       "      <th>WindGustSpd</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>PoorWeather</th>\n",
       "      <th>YR</th>\n",
       "      <th>...</th>\n",
       "      <th>WTE</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>DayOfYear_sin</th>\n",
       "      <th>DayOfYear_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22508</td>\n",
       "      <td>1940-01-01</td>\n",
       "      <td>0.254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>17.222222</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22508</td>\n",
       "      <td>1940-01-02</td>\n",
       "      <td>10.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>16.111111</td>\n",
       "      <td>19.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22508</td>\n",
       "      <td>1940-01-03</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22508</td>\n",
       "      <td>1940-01-04</td>\n",
       "      <td>2.286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22508</td>\n",
       "      <td>1940-01-05</td>\n",
       "      <td>0.254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STA       Date Precip  WindGustSpd    MaxTemp    MinTemp   MeanTemp  \\\n",
       "0  22508 1940-01-01  0.254          NaN  23.333333  17.222222  20.000000   \n",
       "1  22508 1940-01-02  10.16          NaN  23.333333  16.111111  19.444444   \n",
       "2  22508 1940-01-03      T          NaN  23.888889  15.555556  20.000000   \n",
       "3  22508 1940-01-04  2.286          NaN  23.888889  18.333333  21.111111   \n",
       "4  22508 1940-01-05  0.254          NaN  22.222222  15.000000  18.333333   \n",
       "\n",
       "  Snowfall PoorWeather  YR  ...  WTE  Year Month  Day  DayOfYear  DayOfWeek  \\\n",
       "0        0         NaN  40  ...  NaN  1940     1    1          1          0   \n",
       "1        0         NaN  40  ...  NaN  1940     1    2          2          1   \n",
       "2        0         NaN  40  ...  NaN  1940     1    3          3          2   \n",
       "3        0         NaN  40  ...  NaN  1940     1    4          4          3   \n",
       "4        0         NaN  40  ...  NaN  1940     1    5          5          4   \n",
       "\n",
       "   Month_sin  Month_cos DayOfYear_sin  DayOfYear_cos  \n",
       "0        0.5   0.866025      0.017213       0.999852  \n",
       "1        0.5   0.866025      0.034422       0.999407  \n",
       "2        0.5   0.866025      0.051620       0.998667  \n",
       "3        0.5   0.866025      0.068802       0.997630  \n",
       "4        0.5   0.866025      0.085965       0.996298  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(df: pd.DataFrame, target_column: str = 'MeanTemp') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess weather data for a specific station.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame (should be station-specific)\n",
    "        target_column: Name of the target column to predict\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed DataFrame\n",
    "    \"\"\"\n",
    "    df_processed: pd.DataFrame = df.copy()\n",
    "    \n",
    "    # Convert Date column to datetime and extract temporal features\n",
    "    if 'Date' in df_processed.columns:\n",
    "        df_processed['Date'] = pd.to_datetime(df_processed['Date'], errors='coerce')\n",
    "        df_processed = df_processed.sort_values(by='Date')\n",
    "        \n",
    "        # Extract temporal features\n",
    "        df_processed['Year'] = df_processed['Date'].dt.year\n",
    "        df_processed['Month'] = df_processed['Date'].dt.month\n",
    "        df_processed['Day'] = df_processed['Date'].dt.day\n",
    "        df_processed['DayOfYear'] = df_processed['Date'].dt.dayofyear\n",
    "        df_processed['DayOfWeek'] = df_processed['Date'].dt.dayofweek\n",
    "        \n",
    "        # Create cyclical features for seasonality\n",
    "        df_processed['Month_sin'] = np.sin(2 * np.pi * df_processed['Month'] / 12)\n",
    "        df_processed['Month_cos'] = np.cos(2 * np.pi * df_processed['Month'] / 12)\n",
    "        df_processed['DayOfYear_sin'] = np.sin(2 * np.pi * df_processed['DayOfYear'] / 365)\n",
    "        df_processed['DayOfYear_cos'] = np.cos(2 * np.pi * df_processed['DayOfYear'] / 365)\n",
    "    \n",
    "    df_processed = df_processed.reset_index(drop=True)\n",
    "    \n",
    "    # Handle missing values in numeric columns\n",
    "    numeric_cols: List[str] = df_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        if col != target_column:\n",
    "            df_processed[col] = df_processed[col].ffill().bfill()\n",
    "    \n",
    "    # Handle target column separately\n",
    "    if target_column in df_processed.columns:\n",
    "        df_processed[target_column] = df_processed[target_column].ffill().bfill()\n",
    "        df_processed = df_processed.dropna(subset=[target_column])\n",
    "    \n",
    "    print(f\"‚úÖ Data preprocessing completed!\")\n",
    "    print(f\"üìä Processed data shape: {df_processed.shape}\")\n",
    "    print(f\"üéØ Target variable: '{target_column}'\")\n",
    "    \n",
    "    if 'Date' in df_processed.columns:\n",
    "        print(f\"üìÖ Date range: {df_processed['Date'].min()} to {df_processed['Date'].max()}\")\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Preprocess data - using MeanTemp as the target variable\n",
    "df_processed: pd.DataFrame = preprocess_data(df_station, target_column='MeanTemp')\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 6 lag features and 4 rolling statistics\n",
      "üìä Data shape after feature engineering: (0, 50)\n",
      "\n",
      "üìã New features created:\n",
      "['MeanTemp_lag_1', 'MeanTemp_lag_2', 'MeanTemp_lag_3', 'MeanTemp_lag_7', 'MeanTemp_lag_14', 'MeanTemp_lag_30', 'MeanTemp_rolling_mean_7', 'MeanTemp_rolling_std_7', 'MeanTemp_rolling_mean_30', 'MeanTemp_rolling_std_30']\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features(df: pd.DataFrame, target_col: str, lags: List[int] = [1, 2, 3, 7, 14, 30]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create lag features for time series prediction.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        target_col: Target column name\n",
    "        lags: List of lag periods to create\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with lag features\n",
    "    \"\"\"\n",
    "    df_lagged: pd.DataFrame = df.copy()\n",
    "    \n",
    "    for lag in lags:\n",
    "        df_lagged[f'{target_col}_lag_{lag}'] = df_lagged[target_col].shift(lag)\n",
    "    \n",
    "    # Create rolling statistics\n",
    "    df_lagged[f'{target_col}_rolling_mean_7'] = df_lagged[target_col].rolling(window=7, min_periods=1).mean()\n",
    "    df_lagged[f'{target_col}_rolling_std_7'] = df_lagged[target_col].rolling(window=7, min_periods=1).std()\n",
    "    df_lagged[f'{target_col}_rolling_mean_30'] = df_lagged[target_col].rolling(window=30, min_periods=1).mean()\n",
    "    df_lagged[f'{target_col}_rolling_std_30'] = df_lagged[target_col].rolling(window=30, min_periods=1).std()\n",
    "    \n",
    "    # Drop rows with NaN values created by lagging\n",
    "    df_lagged = df_lagged.dropna()\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(lags)} lag features and 4 rolling statistics\")\n",
    "    print(f\"üìä Data shape after feature engineering: {df_lagged.shape}\")\n",
    "    \n",
    "    return df_lagged\n",
    "\n",
    "# Create lag features\n",
    "target_col: str = 'MeanTemp'\n",
    "df_features: pd.DataFrame = create_lag_features(df_processed, target_col, lags=[1, 2, 3, 7, 14, 30])\n",
    "\n",
    "print(\"\\nüìã New features created:\")\n",
    "lag_features: List[str] = [col for col in df_features.columns if 'lag' in col or 'rolling' in col]\n",
    "print(lag_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Selected 0 features for modeling\n",
      "\n",
      "üìã Feature categories:\n",
      "  ‚Ä¢ Lag features: 0\n",
      "  ‚Ä¢ Rolling statistics: 0\n",
      "  ‚Ä¢ Temporal features: 0\n",
      "  ‚Ä¢ Weather features: 0\n",
      "\n",
      "üìä Final modeling dataset shape: (0, 1)\n"
     ]
    }
   ],
   "source": [
    "def select_features(df: pd.DataFrame, target_col: str) -> Tuple[List[str], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Select relevant features for linear regression.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        target_col: Target column name\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (feature names list, DataFrame with selected features)\n",
    "    \"\"\"\n",
    "    # Select numeric features (excluding target and identifiers)\n",
    "    exclude_cols: List[str] = [target_col, 'STA', 'Date', 'YR', 'MO', 'DA']\n",
    "    \n",
    "    feature_cols: List[str] = [col for col in df.select_dtypes(include=[np.number]).columns \n",
    "                                if col not in exclude_cols]\n",
    "    \n",
    "    # Prioritize lag features and temporal features\n",
    "    priority_features: List[str] = [col for col in feature_cols if 'lag' in col or 'rolling' in col \n",
    "                                     or 'Month' in col or 'DayOfYear' in col or 'Year' in col]\n",
    "    \n",
    "    # Add other weather features if available\n",
    "    weather_features: List[str] = ['MaxTemp', 'MinTemp', 'Precip', 'WindGustSpd', 'Snowfall']\n",
    "    available_weather: List[str] = [col for col in weather_features if col in feature_cols]\n",
    "    \n",
    "    # Combine all features\n",
    "    selected_features: List[str] = list(set(priority_features + available_weather))\n",
    "    \n",
    "    # Remove features with too many missing values\n",
    "    valid_features: List[str] = []\n",
    "    for col in selected_features:\n",
    "        if df[col].isnull().sum() / len(df) < 0.5:  # Less than 50% missing\n",
    "            valid_features.append(col)\n",
    "    \n",
    "    print(f\"‚úÖ Selected {len(valid_features)} features for modeling\")\n",
    "    print(\"\\nüìã Feature categories:\")\n",
    "    lag_feats = [f for f in valid_features if 'lag' in f]\n",
    "    rolling_feats = [f for f in valid_features if 'rolling' in f]\n",
    "    temporal_feats = [f for f in valid_features if any(x in f for x in ['Month', 'Day', 'Year'])]\n",
    "    weather_feats = [f for f in valid_features if f in weather_features]\n",
    "    \n",
    "    print(f\"  ‚Ä¢ Lag features: {len(lag_feats)}\")\n",
    "    print(f\"  ‚Ä¢ Rolling statistics: {len(rolling_feats)}\")\n",
    "    print(f\"  ‚Ä¢ Temporal features: {len(temporal_feats)}\")\n",
    "    print(f\"  ‚Ä¢ Weather features: {len(weather_feats)}\")\n",
    "    \n",
    "    return valid_features, df[valid_features + [target_col]].copy()\n",
    "\n",
    "# Select features\n",
    "feature_names: List[str]\n",
    "df_modeling: pd.DataFrame\n",
    "feature_names, df_modeling = select_features(df_features, target_col)\n",
    "\n",
    "print(f\"\\nüìä Final modeling dataset shape: {df_modeling.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Feature matrix shape: (0, 0)\n",
      "üìä Target vector shape: (0,)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m y_train: pd.Series = y[:train_size]\n\u001b[32m     16\u001b[39m y_test: pd.Series = y[train_size:]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Training set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m*\u001b[32m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìä Test set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(X_test)/\u001b[38;5;28mlen\u001b[39m(X)*\u001b[32m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Standardize features\u001b[39;00m\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "# Remove any remaining NaN values\n",
    "df_modeling = df_modeling.dropna()\n",
    "\n",
    "# Split features and target\n",
    "X: pd.DataFrame = df_modeling[feature_names]\n",
    "y: pd.Series = df_modeling[target_col]\n",
    "\n",
    "print(f\"üìä Feature matrix shape: {X.shape}\")\n",
    "print(f\"üìä Target vector shape: {y.shape}\")\n",
    "\n",
    "# Split into train and test sets (80-20 split, preserving temporal order)\n",
    "train_size: int = int(len(X) * 0.8)\n",
    "X_train: pd.DataFrame = X[:train_size]\n",
    "X_test: pd.DataFrame = X[train_size:]\n",
    "y_train: pd.Series = y[:train_size]\n",
    "y_test: pd.Series = y[train_size:]\n",
    "\n",
    "print(f\"\\nüìä Training set size: {len(X_train)} ({(len(X_train)/len(X)*100):.1f}%)\")\n",
    "print(f\"üìä Test set size: {len(X_test)} ({(len(X_test)/len(X)*100):.1f}%)\")\n",
    "\n",
    "# Standardize features\n",
    "scaler: StandardScaler = StandardScaler()\n",
    "X_train_scaled: np.ndarray = scaler.fit_transform(X_train)\n",
    "X_test_scaled: np.ndarray = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Features standardized (mean=0, std=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Linear Regression model\n",
    "print(f\"üöÄ Training Linear Regression model for Station {selected_station_id}...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model: LinearRegression = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training completed!\")\n",
    "print(f\"\\nüìä Model coefficients: {len(model.coef_)} features\")\n",
    "print(f\"üìä Model intercept: {model.intercept_:.4f}\")\n",
    "\n",
    "# Display feature importance (absolute coefficient values)\n",
    "feature_importance: pd.DataFrame = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': model.coef_,\n",
    "    'Abs_Coefficient': np.abs(model.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä Top 10 Most Important Features:\")\n",
    "print(\"=\" * 70)\n",
    "print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(f\"üîÆ Making predictions for Station {selected_station_id}...\")\n",
    "\n",
    "y_train_pred: np.ndarray = model.predict(X_train_scaled)\n",
    "y_test_pred: np.ndarray = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"‚úÖ Predictions completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True values\n",
    "        y_pred: Predicted values\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing performance metrics\n",
    "    \"\"\"\n",
    "    mse: float = mean_squared_error(y_true, y_pred)\n",
    "    rmse: float = np.sqrt(mse)\n",
    "    mae: float = mean_absolute_error(y_true, y_pred)\n",
    "    r2: float = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate MAPE (avoiding division by zero)\n",
    "    mape: float = np.mean(np.abs((y_true - y_pred) / np.where(y_true != 0, y_true, 1))) * 100\n",
    "    \n",
    "    metrics: Dict[str, float] = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2 Score': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_metrics: Dict[str, float] = calculate_metrics(y_train.values, y_train_pred)\n",
    "print(f\"\\nüìä Training Set Metrics - Station {selected_station_id}:\")\n",
    "print(\"=\" * 70)\n",
    "for metric, value in train_metrics.items():\n",
    "    print(f\"  {metric:15s}: {value:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_metrics: Dict[str, float] = calculate_metrics(y_test.values, y_test_pred)\n",
    "print(f\"üéØ Test Set Metrics - Station {selected_station_id}:\")\n",
    "print(\"=\" * 70)\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"  {metric:15s}: {value:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features: pd.DataFrame = feature_importance.head(15)\n",
    "colors = ['#2E86AB' if coef > 0 else '#D62246' for coef in top_features['Coefficient']]\n",
    "\n",
    "plt.barh(range(len(top_features)), top_features['Coefficient'], color=colors)\n",
    "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.title(f'Top 15 Feature Importance - Station {selected_station_id}', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"  ‚Ä¢ Blue bars: Positive correlation (increase in feature ‚Üí increase in temperature)\")\n",
    "print(\"  ‚Ä¢ Red bars: Negative correlation (increase in feature ‚Üí decrease in temperature)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual values\n",
    "plt.figure(figsize=(18, 7))\n",
    "\n",
    "# Training data\n",
    "train_indices: np.ndarray = np.arange(len(y_train))\n",
    "plt.plot(train_indices, y_train.values, label='Actual (Train)', \n",
    "         color='#2E86AB', alpha=0.7, linewidth=1.5)\n",
    "plt.plot(train_indices, y_train_pred, label='Predicted (Train)', \n",
    "         color='#F18F01', alpha=0.7, linewidth=1.5)\n",
    "\n",
    "# Test data\n",
    "test_indices: np.ndarray = np.arange(len(y_train), len(y_train) + len(y_test))\n",
    "plt.plot(test_indices, y_test.values, label='Actual (Test)', \n",
    "         color='#06A77D', alpha=0.7, linewidth=1.5)\n",
    "plt.plot(test_indices, y_test_pred, label='Predicted (Test)', \n",
    "         color='#D62246', alpha=0.7, linewidth=1.5)\n",
    "\n",
    "# Add vertical line to separate train and test\n",
    "plt.axvline(x=len(y_train), color='black', linestyle='--', \n",
    "            linewidth=2, label='Train/Test Split', alpha=0.5)\n",
    "\n",
    "plt.title(f'Temperature Prediction: Actual vs Predicted - Station {selected_station_id}', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Time Steps', fontsize=12)\n",
    "plt.ylabel('Temperature (¬∞C)', fontsize=12)\n",
    "plt.legend(fontsize=10, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in on test predictions\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(y_test.values, label='Actual Temperature', \n",
    "         color='#06A77D', linewidth=2, marker='o', markersize=3, alpha=0.8)\n",
    "plt.plot(y_test_pred, label='Predicted Temperature', \n",
    "         color='#D62246', linewidth=2, marker='s', markersize=3, alpha=0.8)\n",
    "plt.title(f'Test Set: Detailed Comparison - Station {selected_station_id}', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Time Steps', fontsize=12)\n",
    "plt.ylabel('Temperature (¬∞C)', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Predicted vs Actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set\n",
    "axes[0].scatter(y_train.values, y_train_pred, alpha=0.5, s=20, color='#2E86AB')\n",
    "axes[0].plot([y_train.min(), y_train.max()], \n",
    "             [y_train.min(), y_train.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_title(f'Training Set: Predicted vs Actual - Station {selected_station_id}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Actual Temperature (¬∞C)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Temperature (¬∞C)', fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test set\n",
    "axes[1].scatter(y_test.values, y_test_pred, alpha=0.5, s=20, color='#06A77D')\n",
    "axes[1].plot([y_test.min(), y_test.max()], \n",
    "             [y_test.min(), y_test.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1].set_title(f'Test Set: Predicted vs Actual - Station {selected_station_id}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Actual Temperature (¬∞C)', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted Temperature (¬∞C)', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "train_residuals: np.ndarray = y_train.values - y_train_pred\n",
    "test_residuals: np.ndarray = y_test.values - y_test_pred\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Training residuals over time\n",
    "axes[0, 0].plot(train_residuals, color='#2E86AB', alpha=0.7, linewidth=1)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_title(f'Training Residuals Over Time - Station {selected_station_id}', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Time Steps', fontsize=10)\n",
    "axes[0, 0].set_ylabel('Residuals (¬∞C)', fontsize=10)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test residuals over time\n",
    "axes[0, 1].plot(test_residuals, color='#06A77D', alpha=0.7, linewidth=1)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_title(f'Test Residuals Over Time - Station {selected_station_id}', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Time Steps', fontsize=10)\n",
    "axes[0, 1].set_ylabel('Residuals (¬∞C)', fontsize=10)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Training residuals distribution\n",
    "axes[1, 0].hist(train_residuals, bins=50, edgecolor='black', alpha=0.7, color='#2E86AB')\n",
    "axes[1, 0].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_title('Training Residuals Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Residuals (¬∞C)', fontsize=10)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=10)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test residuals distribution\n",
    "axes[1, 1].hist(test_residuals, bins=50, edgecolor='black', alpha=0.7, color='#06A77D')\n",
    "axes[1, 1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_title('Test Residuals Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Residuals (¬∞C)', fontsize=10)\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=10)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Training Residuals - Mean: {train_residuals.mean():.4f}¬∞C, Std: {train_residuals.std():.4f}¬∞C\")\n",
    "print(f\"üìä Test Residuals - Mean: {test_residuals.mean():.4f}¬∞C, Std: {test_residuals.std():.4f}¬∞C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_report(train_metrics: Dict[str, float], test_metrics: Dict[str, float], \n",
    "                        station_id: Optional[int] = None, n_features: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Print comprehensive summary report.\n",
    "    \n",
    "    Args:\n",
    "        train_metrics: Training set metrics\n",
    "        test_metrics: Test set metrics\n",
    "        station_id: Station identifier\n",
    "        n_features: Number of features used\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" \" * 15 + \"üå°Ô∏è  LINEAR REGRESSION TEMPERATURE PREDICTION - SUMMARY REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nüìä MODEL CONFIGURATION:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  ‚Ä¢ Data Source: Summary of Weather.csv\")\n",
    "    print(f\"  ‚Ä¢ Station ID: {station_id}\")\n",
    "    print(f\"  ‚Ä¢ Target Variable: MeanTemp (Mean Temperature)\")\n",
    "    print(f\"  ‚Ä¢ Number of Features: {n_features}\")\n",
    "    print(f\"  ‚Ä¢ Training Samples: {len(X_train)}\")\n",
    "    print(f\"  ‚Ä¢ Test Samples: {len(X_test)}\")\n",
    "    print(f\"  ‚Ä¢ Model Type: Linear Regression (Ordinary Least Squares)\")\n",
    "    print(f\"  ‚Ä¢ Feature Scaling: StandardScaler (mean=0, std=1)\")\n",
    "    \n",
    "    print(\"\\nüìà TRAINING SET PERFORMANCE:\")\n",
    "    print(\"-\" * 80)\n",
    "    for metric, value in train_metrics.items():\n",
    "        print(f\"  ‚Ä¢ {metric:15s}: {value:.6f}\")\n",
    "    \n",
    "    print(\"\\nüéØ TEST SET PERFORMANCE:\")\n",
    "    print(\"-\" * 80)\n",
    "    for metric, value in test_metrics.items():\n",
    "        print(f\"  ‚Ä¢ {metric:15s}: {value:.6f}\")\n",
    "    \n",
    "    print(\"\\nüí° MODEL INSIGHTS:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  ‚Ä¢ Model explains {test_metrics['R2 Score']*100:.2f}% of variance in test data\")\n",
    "    print(f\"  ‚Ä¢ Average prediction error on test set: {test_metrics['MAE']:.4f}¬∞C\")\n",
    "    print(f\"  ‚Ä¢ Mean Absolute Percentage Error: {test_metrics['MAPE']:.2f}%\")\n",
    "    \n",
    "    print(\"\\nüèÜ PERFORMANCE EVALUATION:\")\n",
    "    print(\"-\" * 80)\n",
    "    if test_metrics['R2 Score'] > 0.9:\n",
    "        print(\"  ‚úÖ Excellent model performance! The model captures temperature patterns very well.\")\n",
    "    elif test_metrics['R2 Score'] > 0.7:\n",
    "        print(\"  ‚úÖ Good model performance! The model shows strong predictive capability.\")\n",
    "    elif test_metrics['R2 Score'] > 0.5:\n",
    "        print(\"  ‚ö†Ô∏è  Moderate model performance - consider adding more features or using non-linear models.\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  Poor model performance - linear regression may not be suitable for this data.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print_summary_report(train_metrics, test_metrics, selected_station_id, len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the model\n",
    "model_filename: str = f'linear_regression_model_station_{selected_station_id}.pkl'\n",
    "joblib.dump(model, model_filename)\n",
    "print(f\"‚úÖ Model saved as '{model_filename}'\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_filename: str = f'scaler_station_{selected_station_id}.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"‚úÖ Scaler saved as '{scaler_filename}'\")\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_filename: str = f'lr_predictions_station_{selected_station_id}.csv'\n",
    "predictions_df: pd.DataFrame = pd.DataFrame({\n",
    "    'Station_ID': selected_station_id,\n",
    "    'Actual_Test': y_test.values,\n",
    "    'Predicted_Test': y_test_pred,\n",
    "    'Residuals': test_residuals,\n",
    "    'Absolute_Error': np.abs(test_residuals)\n",
    "})\n",
    "\n",
    "predictions_df.to_csv(predictions_filename, index=False)\n",
    "print(f\"‚úÖ Predictions saved as '{predictions_filename}'\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance_filename: str = f'feature_importance_station_{selected_station_id}.csv'\n",
    "feature_importance.to_csv(feature_importance_filename, index=False)\n",
    "print(f\"‚úÖ Feature importance saved as '{feature_importance_filename}'\")\n",
    "\n",
    "# Save metrics to JSON\n",
    "metrics_filename: str = f'lr_metrics_station_{selected_station_id}.json'\n",
    "metrics_summary: Dict[str, any] = {\n",
    "    'data_source': 'Summary of Weather.csv',\n",
    "    'station_id': int(selected_station_id) if selected_station_id else None,\n",
    "    'target_variable': 'MeanTemp',\n",
    "    'training_metrics': {k: float(v) for k, v in train_metrics.items()},\n",
    "    'test_metrics': {k: float(v) for k, v in test_metrics.items()},\n",
    "    'model_config': {\n",
    "        'model_type': 'Linear Regression',\n",
    "        'n_features': len(feature_names),\n",
    "        'feature_names': feature_names,\n",
    "        'scaler': 'StandardScaler'\n",
    "    },\n",
    "    'data_split': {\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'train_percentage': 80,\n",
    "        'test_percentage': 20\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(metrics_filename, 'w') as f:\n",
    "    json.dump(metrics_summary, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ Metrics saved as '{metrics_filename}'\")\n",
    "print(\"\\nüéâ All results saved successfully!\")\n",
    "print(f\"\\nüìÅ Generated Files for Station {selected_station_id}:\")\n",
    "print(f\"  ‚Ä¢ {model_filename} - Trained Linear Regression model\")\n",
    "print(f\"  ‚Ä¢ {scaler_filename} - Feature scaler\")\n",
    "print(f\"  ‚Ä¢ {predictions_filename} - Test predictions and errors\")\n",
    "print(f\"  ‚Ä¢ {feature_importance_filename} - Feature importance ranking\")\n",
    "print(f\"  ‚Ä¢ {metrics_filename} - Comprehensive metrics and configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Model Comparison with LSTM (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell compares Linear Regression with LSTM results (if available)\n",
    "print(\"üìä Model Comparison: Linear Regression vs LSTM\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison_data: Dict[str, Dict[str, float]] = {\n",
    "    'Linear Regression': test_metrics\n",
    "}\n",
    "\n",
    "# Try to load LSTM metrics if available\n",
    "lstm_metrics_file: str = f'model_metrics_station_{selected_station_id}.json'\n",
    "try:\n",
    "    with open(lstm_metrics_file, 'r') as f:\n",
    "        lstm_data: Dict = json.load(f)\n",
    "        comparison_data['LSTM'] = lstm_data['test_metrics']\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_df: pd.DataFrame = pd.DataFrame(comparison_data).T\n",
    "    print(\"\\nüìä Performance Comparison:\")\n",
    "    print(comparison_df.to_string())\n",
    "    \n",
    "    # Visualize comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    metrics_to_plot: List[str] = ['RMSE', 'MAE', 'R2 Score', 'MAPE']\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_to_plot):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        values = [comparison_data[model][metric] for model in comparison_data.keys()]\n",
    "        colors = ['#2E86AB', '#F18F01']\n",
    "        ax.bar(comparison_data.keys(), values, color=colors[:len(values)])\n",
    "        ax.set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(metric, fontsize=10)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(values):\n",
    "            ax.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.suptitle(f'Model Performance Comparison - Station {selected_station_id}', \n",
    "                 fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° Key Insights:\")\n",
    "    print(\"-\" * 70)\n",
    "    if comparison_data['Linear Regression']['R2 Score'] > comparison_data['LSTM']['R2 Score']:\n",
    "        print(\"  ‚Ä¢ Linear Regression outperforms LSTM on this dataset\")\n",
    "        print(\"  ‚Ä¢ This suggests the relationship is primarily linear\")\n",
    "    else:\n",
    "        print(\"  ‚Ä¢ LSTM outperforms Linear Regression on this dataset\")\n",
    "        print(\"  ‚Ä¢ This suggests non-linear temporal patterns are important\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\n‚ö†Ô∏è  LSTM metrics file not found. Run the LSTM notebook first for comparison.\")\n",
    "    print(f\"   Expected file: {lstm_metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### ‚úÖ What We Accomplished:\n",
    "\n",
    "1. **Station-Specific Analysis**\n",
    "   - Loaded weather data with station identification (STA column)\n",
    "   - Selected and processed data for a specific weather station\n",
    "   - Created station-specific models and results\n",
    "\n",
    "2. **Feature Engineering**\n",
    "   - Created lag features (1, 2, 3, 7, 14, 30 days)\n",
    "   - Generated rolling statistics (7-day and 30-day windows)\n",
    "   - Extracted temporal features (year, month, day, cyclical encodings)\n",
    "   - Selected relevant weather features (MaxTemp, MinTemp, Precip, etc.)\n",
    "\n",
    "3. **Model Development**\n",
    "   - Built Linear Regression model with StandardScaler normalization\n",
    "   - Trained on 80% of data, tested on 20%\n",
    "   - Analyzed feature importance through coefficients\n",
    "\n",
    "4. **Model Evaluation**\n",
    "   - Calculated comprehensive metrics: MSE, RMSE, MAE, R¬≤ Score, MAPE\n",
    "   - Analyzed residuals and error distributions\n",
    "   - Visualized predictions vs actual values\n",
    "   - Compared with LSTM performance (if available)\n",
    "\n",
    "### üéØ Key Features:\n",
    "- **Interpretability**: Linear coefficients show direct feature impact\n",
    "- **Efficiency**: Fast training and prediction (no iterative optimization)\n",
    "- **Baseline**: Provides strong baseline for comparison with complex models\n",
    "- **Feature Insights**: Reveals which features are most predictive\n",
    "\n",
    "### üìä Linear Regression vs LSTM:\n",
    "\n",
    "**Linear Regression Advantages:**\n",
    "- Faster training (no backpropagation)\n",
    "- More interpretable (clear feature weights)\n",
    "- No hyperparameter tuning needed\n",
    "- Works well when relationships are linear\n",
    "\n",
    "**LSTM Advantages:**\n",
    "- Captures non-linear patterns\n",
    "- Learns complex temporal dependencies\n",
    "- Better for long-term forecasting\n",
    "- Handles sequential patterns automatically\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "1. **Regularization**: Try Ridge or Lasso regression to reduce overfitting\n",
    "2. **Polynomial Features**: Add interaction terms and polynomial features\n",
    "3. **Multi-Station Models**: Train models for multiple stations and compare\n",
    "4. **Ensemble Methods**: Combine Linear Regression with LSTM predictions\n",
    "5. **Time Series Cross-Validation**: Use rolling window validation for robust evaluation\n",
    "\n",
    "### üìö Resources:\n",
    "- [Scikit-learn Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- [Time Series Feature Engineering](https://www.kaggle.com/learn/time-series)\n",
    "- [Regression Metrics Guide](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
